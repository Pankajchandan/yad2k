{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import colorsys\n",
    "import imghdr\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from yad2k.models.keras_yolo import yolo_eval, yolo_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(im):\n",
    "    image = Image.fromarray(im)\n",
    "    \n",
    "    sess = K.get_session()  # TODO: Remove dependence on Tensorflow session.\n",
    "    model_path = os.path.expanduser('model_data/yolo.h5')\n",
    "    assert model_path.endswith('.h5'), 'Keras model must be a .h5 file.'\n",
    "    anchors_path = os.path.expanduser('model_data/yolo_anchors.txt')\n",
    "    classes_path = os.path.expanduser('model_data/coco_classes.txt')\n",
    "    \n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "        try:\n",
    "            anchors = [float(x) for x in anchors.split(',')]\n",
    "            anchors = np.array(anchors).reshape(-1, 2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    yolo_model = load_model(model_path)\n",
    "\n",
    "    # Verify model, anchors, and classes are compatible\n",
    "    num_classes = len(class_names)\n",
    "    num_anchors = len(anchors)\n",
    "    # TODO: Assumes dim ordering is channel last\n",
    "    model_output_channels = yolo_model.layers[-1].output_shape[-1]\n",
    "    assert model_output_channels == num_anchors * (num_classes + 5), \\\n",
    "        'Mismatch between model and given anchor and class sizes. ' \\\n",
    "        'Specify matching anchors and classes with --anchors_path and ' \\\n",
    "        '--classes_path flags.'\n",
    "    print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "    # Check if model is fully convolutional, assuming channel last order.\n",
    "    model_image_size = yolo_model.layers[0].input_shape[1:3]\n",
    "    is_fixed_size = model_image_size != (None, None)\n",
    "\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    hsv_tuples = [(x / len(class_names), 1., 1.)\n",
    "                  for x in range(len(class_names))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "            colors))\n",
    "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    random.seed(None)  # Reset seed to default.\n",
    "\n",
    "    # Generate output tensor targets for filtered bounding boxes.\n",
    "    # TODO: Wrap these backend operations with Keras layers.\n",
    "    yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "    input_image_shape = K.placeholder(shape=(2, ))\n",
    "    boxes, scores, classes = yolo_eval(\n",
    "        yolo_outputs,\n",
    "        input_image_shape,\n",
    "        score_threshold=.3,\n",
    "        iou_threshold=.5)\n",
    "\n",
    "    if is_fixed_size:  # TODO: When resizing we can use minibatch input.\n",
    "        resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "    else:\n",
    "        # Due to skip connection + max pooling in YOLO_v2, inputs must have\n",
    "        # width and height as multiples of 32.\n",
    "        new_image_size = (image.width - (image.width % 32),\n",
    "                            image.height - (image.height % 32))\n",
    "        resized_image = image.resize(new_image_size, Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "    out_boxes, out_scores, out_classes = sess.run(\n",
    "        [boxes, scores, classes],\n",
    "        feed_dict={\n",
    "            yolo_model.input: image_data,\n",
    "            input_image_shape: [image.size[1], image.size[0]],\n",
    "            K.learning_phase(): 0\n",
    "        })\n",
    "\n",
    "    font = ImageFont.truetype(\n",
    "        font='font/FiraMono-Medium.otf',\n",
    "        size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        \n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [left + i, top + i, right - i, bottom - i],\n",
    "                outline=colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "    sess.close()\n",
    "\n",
    "    return np.array(image.getdata(),\n",
    "                    np.uint8).reshape(image.size[1], image.size[0], 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 6] The handle is invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1b4f3bbde619>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0m_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-1b4f3bbde619>\u001b[0m in \u001b[0;36m_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mproject_video_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'project_video_output.mp4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mclip1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"videos/project_video.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mlane_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time lane_clip.write_videofile(project_video_output, audio=False)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[0;32m     79\u001b[0m                                          \u001b[0mtarget_resolution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_resolution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                                          \u001b[0mresize_algo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresize_algorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                                          fps_source=fps_source)\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# Make some of the reader's attributes accessible from the clip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[1;32m---> 32\u001b[1;33m                                    fps_source)\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'video_fps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'video_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py\u001b[0m in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mpopen_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"creationflags\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0x08000000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpopen_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    840\u001b[0m                  pass_fds=()):\n\u001b[0;32m    841\u001b[0m         \u001b[1;34m\"\"\"Create new Popen instance.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m         \u001b[1;31m# Held while anything is calling waitpid before returncode has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m         \u001b[1;31m# updated to prevent clobbering returncode if wait() or poll() are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_cleanup\u001b[1;34m()\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_active\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_deadstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_internal_poll\u001b[1;34m(self, _deadstate, _WaitForSingleObject, _WAIT_OBJECT_0, _GetExitCodeProcess)\u001b[0m\n\u001b[0;32m   1257\u001b[0m             \"\"\"\n\u001b[0;32m   1258\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0m_WaitForSingleObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_WAIT_OBJECT_0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_GetExitCodeProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 6] The handle is invalid"
     ]
    }
   ],
   "source": [
    "def _main():\n",
    "    \n",
    "    test_path = os.path.expanduser('videos')\n",
    "    output_path = os.path.expanduser('out')\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        print('Creating output path {}'.format(output_path))\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    \n",
    "    #image = mpimg.imread('images/traffic3.jpg')\n",
    "    #final = pipeline(image)\n",
    "    #final.save('out/test.jpg', quality=90)\n",
    "    \n",
    "    import imageio\n",
    "    from moviepy.editor import VideoFileClip\n",
    "    project_video_output = 'project_video_output.mp4'\n",
    "    clip1 = VideoFileClip(\"videos/project_video.mp4\")\n",
    "    lane_clip = clip1.fl_image(pipeline)\n",
    "    %time lane_clip.write_videofile(project_video_output, audio=False)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    _main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
